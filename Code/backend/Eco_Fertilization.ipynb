{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"hotpink\">Eco_Fertilization</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BestTimeToFertilize Module\n",
    "* Using <a href=\"https://www.weatherbit.io/api/weather-forecast-16-day\">Weatherbit | 16 Day Forecast</a>\n",
    "* Acessing 7 days of forecast data in json format.\n",
    "* Data requests\n",
    "    1. temperature (Celsius)\n",
    "    2. humidity (relative humidity in %)\n",
    "    3. rainfall (mm)\n",
    "* API call format: ```https://api.weatherbit.io/v2.0/forecast/daily?city=Raleigh,NC&key=API_KEY&days=5```\n",
    "* Effective Rainfall: https://www.fao.org/3/S2022E/s2022e03.htm\n",
    "* Rates of rainfall:\n",
    "    * Drizzle, very small droplets.\n",
    "    * Slight (fine) drizzle: Detectable as droplets only on the face, car windscreens and windows.\n",
    "    * Moderate drizzle: Windows and other surfaces stream with water.\n",
    "    * Heavy (thick) drizzle: Impairs visibility and is measurable in a raingauge, rates up to 1 mm per hour.\n",
    "    * Rain, drops of appreciable size and may be described as small to large drops. It is possible to have rain drops within drizzle!\n",
    "    * Slight rain: Less than 0.5 mm per hour.\n",
    "    * Moderate rain: Greater than 0.5 mm per hour, but less than 4.0 mm per hour.\n",
    "    * Heavy rain: Greater than 4 mm per hour, but less than 8 mm per hour.\n",
    "    * Very heavy rain: Greater than 8 mm per hour.\n",
    "    * Slight shower: Less than 2 mm per hour.\n",
    "    * Moderate shower: Greater than 2 mm, but less than 10 mm per hour.\n",
    "    * Heavy shower: Greater than 10 mm per hour, but less than 50 mm per hour.\n",
    "    * Violent shower: Greater than 50 mm per hour.\n",
    "* Weather API Codes/Icons: https://www.weatherbit.io/api/codes \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fertilization \n",
    "* Heavy and prolonged rain can wash away recently applied fertilizer. It is also important that the water within the first 24 hours (upto 48 hours) be evenly distributed.\n",
    "* Rainfall of greater than ½ inch (12.7 mm) puts your fertilizer at risk. \n",
    "* Urea converts to ammonium ion within 5 to six days by urease enzyme and it takes another 5 to. Six days to convert it in nitrate by soil bacteria . After this plant roots can absorb it properly but all these are also affected by temp, moisture and soil texture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version Info\n",
    "* Python version: 3.8.10\n",
    "* requests module version: 2.27.1\n",
    "* json module version: 2.0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import json as js\n",
    "from time import sleep\n",
    "\n",
    "# !python3 --version\n",
    "# print(\"requests\", rq.__version__)\n",
    "# print(\"json\", js.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestTimeToFertilize:\n",
    "    __BASE_URL = \"https://api.weatherbit.io/v2.0/forecast/daily?\"\n",
    "    __API_KEY = \"480589e42e7c4352abe4fe25bd398ab0\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, city_name = 'Bangalore', state_name = 'Karnataka', days = 7):\n",
    "        self.city_name = '+'.join(city_name.lower().strip().split())\n",
    "        self.state_name = '+'.join(state_name.lower().strip().split())\n",
    "        self.country_name = 'IN'\n",
    "        self.days = days\n",
    "        self.response = None\n",
    "        self.response_code = None\n",
    "        self.weather_data = list()\n",
    "        \n",
    "    def api_caller(self):\n",
    "        try:\n",
    "            complete_url = \"{0}city={1}&state={2}&country={3}&key={4}&days={5}\".format(self.__BASE_URL, self.city_name, self.state_name, self.country_name, self.__API_KEY, self.days)\n",
    "            print(complete_url)\n",
    "            #while self.response == None:\n",
    "            self.response = rq.get(complete_url)\n",
    "            sleep(5)\n",
    "            self.response_code = self.response.status_code\n",
    "            return self.response_code\n",
    "        except Exception as msg:\n",
    "            print(\"api_caller():\", msg)\n",
    "            return -1\n",
    "        \n",
    "    \n",
    "    def is_api_call_success(self):\n",
    "        if self.response_code == 200:\n",
    "            return True\n",
    "        elif self.response_code == 204:\n",
    "            print('Content Not available, error code 204')\n",
    "        return False\n",
    "    \n",
    "\n",
    "    def json_file_bulider(self):\n",
    "        try:\n",
    "            json_obj = self.response.json()\n",
    "            with open('weather_data.json', 'w') as file:\n",
    "                js.dump(json_obj, file, indent = 1, sort_keys = True)\n",
    "            print(\"weather_data.json file build successfully\")\n",
    "        except Exception as msg:\n",
    "            print(\"json_bulider():\", msg)\n",
    "            \n",
    "    \n",
    "    def best_time_fertilize(self):\n",
    "        json_obj = self.response.json()\n",
    "        \n",
    "        print(\"City:\", json_obj['city_name'], \"\\n\")\n",
    "\n",
    "        prolonged_precip = 0\n",
    "        prolonged_prob = 0\n",
    "        heavy_rain_2d = False\n",
    "        heavy_rain_chance_2d = 0\n",
    "        precip_2d = 0\n",
    "        precip_chance_2d = 0\n",
    "        \n",
    "        for i in range(self.days):\n",
    "            date = json_obj['data'][i]['datetime']\n",
    "            temp = json_obj['data'][i]['temp']\n",
    "            rh = json_obj['data'][i]['rh']\n",
    "            precip = json_obj['data'][i]['precip']\n",
    "            prob = json_obj['data'][i]['pop']\n",
    "            w_code = json_obj['data'][i]['weather']['code']\n",
    "            w_desc = json_obj['data'][i]['weather']['description']\n",
    "            i_code = json_obj['data'][i]['weather']['icon']\n",
    "            prolonged_precip += precip\n",
    "            prolonged_prob += prob\n",
    "\n",
    "            count_2d = 0\n",
    "            if i < 2:\n",
    "                precip_2d += precip\n",
    "                precip_chance_2d += prob\n",
    "                if w_code in [202, 233, 502, 521, 522]:\n",
    "                    heavy_rain_2d = True\n",
    "                    heavy_rain_chance_2d += prob\n",
    "                    count_2d += 1\n",
    "                    heavy_rain_chance_2d //= count_2d\n",
    "            \n",
    "            di = {\n",
    "                  \"Date\": str(date), \n",
    "                  \"Temperature\": str(temp), \n",
    "                  \"Relative Humidity\": str(rh), \n",
    "                  \"Rainfall\": str(precip), \n",
    "                  \"Probability of Precipitation\": str(prob),\n",
    "                  \"Weather code\": str(w_code),\n",
    "                  \"Weather Description\": str(w_desc),\n",
    "                  \"Icon code\": str(i_code)\n",
    "                 }\n",
    "            self.weather_data.append(di)\n",
    "            \n",
    "            print(\"Date:\", date)\n",
    "            print(\"Temperature:\", temp)\n",
    "            print(\"Relative Humidity:\", rh)\n",
    "            print(\"Rainfall:\", precip)\n",
    "            print(\"Probability of Precipitation:\", prob)\n",
    "            print(\"Weather code:\", w_code, \"->\", w_desc)\n",
    "            print()\n",
    "\n",
    "        prolonged_prob //= self.days\n",
    "        precip_chance_2d //= 2\n",
    "\n",
    "        print(\"-\"*80)\n",
    "        print(\"The amount of rain for 2 days, counting today:\", precip_2d)\n",
    "        print(\"Chances of rain for 2 days, counting today:\", precip_chance_2d)\n",
    "        print()\n",
    "\n",
    "        if heavy_rain_2d:\n",
    "            print(\"*\"*21, \"Warning !!!\", \"*\"*21)\n",
    "            print(\"Heavy Rain Chances:\", heavy_rain_chance_2d)\n",
    "            print(\"Heavy Rainfall puts your fertilizer at risk.\")\n",
    "            print(\"*\"*21, \"Warning !!!\", \"*\"*21)\n",
    "\n",
    "        print(\"Prolonged Precipitation:\", prolonged_precip)\n",
    "        print(\"Prolonged Precipitation Probability:\", prolonged_prob)\n",
    "        print()\n",
    "\n",
    "        if prolonged_precip > 12.7 and prolonged_prob >= 50:\n",
    "            print(\"*\"*21, \"Warning !!!\", \"*\"*21)\n",
    "            print(\"Prolonged Rainfall of greater than 12.7 mm puts your fertilizer at risk.\")\n",
    "            print(\"*\"*21, \"Warning !!!\", \"*\"*21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.weatherbit.io/v2.0/forecast/daily?city=ahmedabad&state=gujarat&country=IN&key=480589e42e7c4352abe4fe25bd398ab0&days=7\n",
      "403\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    obj = BestTimeToFertilize('Ahmedabad', 'Gujarat')\n",
    "    print(obj.api_caller())\n",
    "    if obj.is_api_call_success():\n",
    "        obj.best_time_fertilize()\n",
    "        obj.json_file_bulider()\n",
    "#         print(obj.weather_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version Info\n",
    "* numpy 1.22.3\n",
    "* pandas 1.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m \u001b[38;5;66;03m# linear algebra\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m \u001b[38;5;66;03m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m \u001b[38;5;66;03m# data visualization\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import warnings\n",
    "\n",
    "# enable the inline plotting, where the plots/graphs will be displayed just below the \n",
    "# cell where your plotting commands are written\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# print(\"numpy\", np.__version__)\n",
    "# print(\"pandas\", pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'Nutrient_recommendation.csv'\n",
    "df = pd.read_csv(data, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view dimensions of dataset\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column names\n",
    "\n",
    "df.columns = ['Crop', 'Temperature', 'Humidity', 'Rainfall', 'Label_N', 'Label_P', 'Label_K']\n",
    "df.drop(df.index[:1], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View summary of dataset\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values in variables\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare feature vector and target variable\n",
    "X = df.drop(['Label_N', 'Label_P', 'Label_K'], axis=1)\n",
    "\n",
    "y1 = df['Label_N']\n",
    "y2 = df['Label_P']\n",
    "y3 = df['Label_K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of X_train and X_test\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping of crop(string) to int type\n",
    "mapping = dict()\n",
    "\n",
    "# writing the mapping in a file\n",
    "with open(\"mapped_crops.csv\", \"w\") as fh:\n",
    "    fh.write(\"Crops,Key\\n\")\n",
    "    for i, crop in enumerate(np.unique(df[['Crop']]), 1):\n",
    "        mapping[crop] =  i\n",
    "        fh.write(\"%s,%d\\n\" % (crop, i))\n",
    "    mapping['NA'] = np.nan\n",
    "    fh.write(\"NA,nan\")\n",
    "    \n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import category encoders\n",
    "import category_encoders as ce\n",
    "\n",
    "ordinal_cols_mapping = [{\"col\": \"Crop\", \"mapping\": mapping}, ]\n",
    "\n",
    "# encode categorical variables with ordinal encoding\n",
    "encoder = ce.OrdinalEncoder(cols = 'Crop', mapping = ordinal_cols_mapping, return_df = True)\n",
    "\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "X_test = encoder.transform(X_test)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    " \n",
    "# n_estimators = The number of trees in the forest.\n",
    "regressor = RandomForestRegressor(n_estimators = 50, random_state = 0)\n",
    " \n",
    "# fit the model\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict the Test set results\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the loss after training\n",
    "* Let us now calculate the loss between the actual target values in the testing set and the values predicted by the model with the use of a cost function called the Root Mean Square Error (RMSE).\n",
    "<img src=\"https://miro.medium.com/max/460/0*rJwdJuCjM3fqfCIM.png\">\n",
    "* The RMSE of a model determines the absolute fit of the model to the data. In other words, it indicates how close the actual data points are to the model’s predicted values. A low value of RMSE indicates a better fit and is a good measure for determining the accuracy of the model’s predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "rmse = float(format(np.sqrt(metrics.mean_squared_error(y_test, y_pred)), '.3f'))\n",
    "print(\"\\nRMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If set to -1, all CPUs are used, This parameter is used to specify how many concurrent \n",
    "# processes or threads should be used for routines that are parallelized\n",
    "\n",
    "model = RandomForestRegressor(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimators = np.arange(10, 200, 10)\n",
    "scores = []\n",
    "for n in estimators:\n",
    "    model.set_params(n_estimators=n)\n",
    "    model.fit(X_train, y_train)\n",
    "    scores.append(model.score(X_test, y_test))\n",
    "plt.title(\"Effect of n_estimators\")\n",
    "plt.xlabel(\"n_estimator\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.plot(estimators, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "* N: 0.871\n",
    "* P: 0.926\n",
    "* K: 0.995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_arr = [round(sc, 3) for sc in scores]\n",
    "unique, counts = np.unique(scores_arr, return_counts = True)\n",
    "\n",
    "max_count = max(counts)\n",
    "accuracy = -1\n",
    "for uni, count in zip(unique, counts):\n",
    "    # print(uni, count)\n",
    "    if count == max_count:\n",
    "        accuracy = uni\n",
    "\n",
    "print(\"Model accuracy: %.3f\" % (accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPKEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn import metrics\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPKEstimator:\n",
    "    def __init__(self, data = 'Nutrient_recommendation.csv', ):\n",
    "        self.df = pd.read_csv(data, header=None)\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        \n",
    "    \n",
    "    def renameCol(self):\n",
    "        self.df.columns = ['Crop', 'Temperature', 'Humidity', 'Rainfall', 'Label_N', 'Label_P', 'Label_K']\n",
    "        self.df.drop(self.df.index[:1], inplace=True)\n",
    "    \n",
    "    \n",
    "    def cropMapper(self):\n",
    "        # create mapping of crop(string) to int type\n",
    "        mapping = dict()\n",
    "\n",
    "        with open(\"mapped_crops.csv\", \"w\") as fh:\n",
    "            fh.write(\"Crops,Key\\n\")\n",
    "            for i, crop in enumerate(np.unique(self.df[['Crop']]), 1):\n",
    "                mapping[crop] =  i\n",
    "                fh.write(\"%s,%d\\n\" % (crop, i))\n",
    "            mapping['NA'] = np.nan\n",
    "            fh.write(\"NA,nan\")\n",
    "        # print(mapping)\n",
    "        \n",
    "        ordinal_cols_mapping = [{\"col\": \"Crop\", \"mapping\": mapping}, ]\n",
    "        encoder = ce.OrdinalEncoder(cols = 'Crop', mapping = ordinal_cols_mapping, return_df = True)\n",
    "        return mapping, encoder\n",
    "    \n",
    "    \n",
    "    def estimator(self, crop, temp, humidity, rainfall, y_label):\n",
    "        X = self.df.drop(['Label_N', 'Label_P', 'Label_K'], axis=1)\n",
    "        y = self.df[y_label]\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "        \n",
    "        mapping, encoder = self.cropMapper()\n",
    "        self.X_train = encoder.fit_transform(self.X_train)\n",
    "        self.X_test = encoder.transform(self.X_test)\n",
    "        \n",
    "        regressor = RandomForestRegressor(n_estimators = 50, random_state = 0)\n",
    "        regressor.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        # y_pred = regressor.predict(self.X_test)\n",
    "        query = [mapping[crop.strip().lower()], temp, humidity, rainfall]\n",
    "        y_pred = regressor.predict([query])\n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "    def accuracyCalculator(self):\n",
    "        model = RandomForestRegressor(n_jobs=-1)\n",
    "        estimators = np.arange(10, 200, 10)\n",
    "        scores = []\n",
    "        for n in estimators:\n",
    "            model.set_params(n_estimators=n)\n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            scores.append(model.score(self.X_test, self.y_test))\n",
    "        \n",
    "        scores_arr = [round(sc, 3) for sc in scores]\n",
    "        unique, counts = np.unique(scores_arr, return_counts = True)\n",
    "\n",
    "        max_count = max(counts)\n",
    "        accuracy = -1\n",
    "        for uni, count in zip(unique, counts):\n",
    "            # print(uni, count)\n",
    "            if count == max_count:\n",
    "                accuracy = uni\n",
    "\n",
    "        # print(\"Model accuracy: %.2f\" % (accuracy))\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    obj = NPKEstimator()\n",
    "    obj.renameCol()\n",
    "    # 'Label_N', 'Label_P', 'Label_K'\n",
    "    # rice,21.94766735,80.97384195,213.3560921,67,59,41\n",
    "    crop, temp, humidity, rainfall, y_label = 'rice',21.94766735,80.97384195,213.3560921,'Label_N'\n",
    "    res = obj.estimator(crop, temp, humidity, rainfall, y_label)\n",
    "    print(y_label, \":\", res[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
